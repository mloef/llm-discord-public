{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic text search using embeddings\n",
    "\n",
    "We can search through all our reviews semantically in a very efficient manner and at very low cost, by simply embedding our search query, and then finding the most similar reviews. The dataset is created in the [Obtain_dataset Notebook](Obtain_dataset.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docutils\n",
      "  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: docutils\n",
      "Successfully installed docutils-0.19\n"
     ]
    }
   ],
   "source": [
    "!pip install docutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown2\n",
    "import docutils.core\n",
    "import os\n",
    "from html.parser import HTMLParser\n",
    "from io import StringIO\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def load_docs_from_dir(directory):\n",
    "    docs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".rst\") or filename.endswith(\".md\"):\n",
    "            with open(os.path.join(directory, filename)) as f:\n",
    "                docs.append(parse_doc(f.read(), filename.split(\".\")[-1]))\n",
    "    return docs\n",
    "\n",
    "def parse_doc(doc, type):\n",
    "    if type == \"rst\":\n",
    "        pass#return docutils.core.publish_string(doc, writer_name='html')\n",
    "    elif type == \"md\":\n",
    "        return strip_tags(markdown2.markdown(doc))\n",
    "    else:\n",
    "        raise Exception(\"Unknown file type: \" + type)\n",
    "\n",
    "#os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "dirs = [\"eth\", \"uniswap\", \"solidity_hierarchical\"]\n",
    "#print(os.getcwd())\n",
    "\n",
    "docs = []\n",
    "for dir in dirs:\n",
    "    docs.extend(load_docs_from_dir(\"data/\" + dir))\n",
    "\n",
    "#os.chdir(\"data/solidity_hierarchical\")\n",
    "#docs.extend(load_docs_from_dir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in docs if doc is not None]\n",
    "\n",
    "subsequences = []\n",
    "\n",
    "excess_length = 0\n",
    "#produce subsequences from each document\n",
    "for doc in docs:\n",
    "    doc = doc.split(\".\")\n",
    "    for sentence in doc:\n",
    "        tokens = sentence.split(\" \")\n",
    "        if len(tokens) > 500:\n",
    "            subsequences += sentence.split(\"\\n\")\n",
    "        else:\n",
    "            subsequences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequences = [subsequence for subsequence in subsequences if len(subsequence.split(\" \")) > 2 and len(subsequence.split(\" \")) < 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(min([len(s.split(\" \")) for s in subsequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsequence in subsequences:\n",
    "    if len(subsequence.split(\" \")) > 3000:\n",
    "        print(subsequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embeddings, cosine_similarity\n",
    "\n",
    "embeddings = []\n",
    "#split the subsequences into batches of 2048 and iterate through them\n",
    "for i in range(0, len(subsequences), 2048):\n",
    "    #get the embeddings for the current batch\n",
    "    split_subsequences = subsequences[i:i+2048]\n",
    "    #add them to embeddings\n",
    "    try:\n",
    "        embeddings += get_embeddings(\n",
    "        split_subsequences,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    except Exception as e:\n",
    "        print(split_subsequences)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"text\": subsequences, \"embeddings\": embeddings})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\ntitle: Ethash\\ndescription: A detailed loo...</td>\n",
       "      <td>[-0.0025863207411020994, 0.034494005143642426,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nlang: en\\n\\n\\n   Ethash was Ethereum's pro...</td>\n",
       "      <td>[-0.0010527808917686343, 0.0034272498451173306...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proof-of-work has now been switched off entir...</td>\n",
       "      <td>[0.006531394086778164, -0.026499561965465546, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Read more on The Merge, proof-of-stake and st...</td>\n",
       "      <td>[0.011598732322454453, -0.010688896290957928, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This page is for historical interest! \\n\\n\\nE...</td>\n",
       "      <td>[-0.010270166210830212, 0.010270166210830212, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\n\\ntitle: Ethash\\ndescription: A detailed loo...   \n",
       "1  \\n\\nlang: en\\n\\n\\n   Ethash was Ethereum's pro...   \n",
       "2   Proof-of-work has now been switched off entir...   \n",
       "3   Read more on The Merge, proof-of-stake and st...   \n",
       "4   This page is for historical interest! \\n\\n\\nE...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.0025863207411020994, 0.034494005143642426,...  \n",
       "1  [-0.0010527808917686343, 0.0034272498451173306...  \n",
       "2  [0.006531394086778164, -0.026499561965465546, ...  \n",
       "3  [0.011598732322454453, -0.010688896290957928, ...  \n",
       "4  [-0.010270166210830212, 0.010270166210830212, ...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29431"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the df to a csv file\n",
    "df.to_csv(\"data/embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30190"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29431"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28672"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subsequences)//2048*2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "759"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "29431-28672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30190"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "759+29431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings[:29431]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29431"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b9836b3d212eb7a794f200ba4132a32c8ca060461674b71c38ec53ef2676989"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
