{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic text search using embeddings\n",
    "\n",
    "We can search through all our reviews semantically in a very efficient manner and at very low cost, by simply embedding our search query, and then finding the most similar reviews. The dataset is created in the [Obtain_dataset Notebook](Obtain_dataset.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docutils\n",
      "  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: docutils\n",
      "Successfully installed docutils-0.19\n"
     ]
    }
   ],
   "source": [
    "!pip install docutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown2\n",
    "import docutils.core\n",
    "import os\n",
    "from html.parser import HTMLParser\n",
    "from io import StringIO\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def load_docs_from_dir(directory):\n",
    "    docs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".rst\") or filename.endswith(\".md\"):\n",
    "            with open(os.path.join(directory, filename)) as f:\n",
    "                docs.append(parse_doc(f.read(), filename.split(\".\")[-1]))\n",
    "    return docs\n",
    "\n",
    "def parse_doc(doc, type):\n",
    "    if type == \"rst\":\n",
    "        pass#return docutils.core.publish_string(doc, writer_name='html')\n",
    "    elif type == \"md\":\n",
    "        return strip_tags(markdown2.markdown(doc))\n",
    "    else:\n",
    "        raise Exception(\"Unknown file type: \" + type)\n",
    "\n",
    "#os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "dirs = [\"eth\", \"uniswap\", \"solidity_hierarchical\"]\n",
    "#print(os.getcwd())\n",
    "\n",
    "docs = []\n",
    "for dir in dirs:\n",
    "    docs.extend(load_docs_from_dir(\"data/\" + dir))\n",
    "\n",
    "#os.chdir(\"data/solidity_hierarchical\")\n",
    "#docs.extend(load_docs_from_dir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in docs if doc is not None]\n",
    "\n",
    "subsequences = []\n",
    "\n",
    "excess_length = 0\n",
    "#produce subsequences of 100 tokens from each document. subsequences should be 50% overlapping\n",
    "for doc in docs:\n",
    "    doc = doc.split(\".\")\n",
    "    for sentence in doc:\n",
    "        tokens = sentence.split(\" \")\n",
    "    subsequences += doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_data = []\n",
    "\n",
    "#produce training data from subsequences by taking every 2nd sequence as the label\n",
    "for i in range(0, len(subsequences)-1):\n",
    "    prompt = subsequences[i]\n",
    "    completion = \" \" + subsequences[i + 1]\n",
    "    if len((prompt + completion).split(\" \")) > 2048:\n",
    "        tokens = (prompt + completion).split(\" \")[:2048]\n",
    "        prompt = \" \".join(tokens[:1024])\n",
    "        completion = \" \" + \" \".join(tokens[1024:])\n",
    "    training_data.append({\"prompt\": prompt, \"completion\": completion})\n",
    "\n",
    "#save training data to file\n",
    "with open(\"data/training_data.jsonl\", \"w\") as f:\n",
    "    for data in training_data:\n",
    "        f.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample and save training data to file\n",
    "with open(\"data/test_training_data.jsonl\", \"w\") as f:\n",
    "    for data in training_data[::100]:\n",
    "        f.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470916"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(entry['prompt'].split(\" \")) + len(entry['completion'].split(\" \")) for entry in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.69078664565124"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1470916/27916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.29"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1443000/1000*0.0300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27916"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b9836b3d212eb7a794f200ba4132a32c8ca060461674b71c38ec53ef2676989"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
